{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def composition(k, text):\n",
    "    composition_list = []\n",
    "    for i in range(len(text)-k+1):\n",
    "        composition_list.append(text[i:i+k])\n",
    "    #composition_list.sort()\n",
    "    return composition_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = composition(100, dna_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'1': [3, 1], '2': [1, 3], '3': [2, 2], '4': [3, 1], '5': [1, 3]})"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjency_list_degree_list(['1->2,3,5','2->4','3->2,5','4->1,2,5','5->3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genome_path(patterns):\n",
    "    genome_path = ''\n",
    "    genome_path += patterns[0]\n",
    "    for i in range(len(patterns)-1):\n",
    "        genome_path += patterns[i+1][-1]\n",
    "    return genome_path\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAATGCCCACACACGATATCGCTA'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome_path(sample_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def overlap_graph(patterns):\n",
    "    overlapGraph = defaultdict(list)\n",
    "    for i in range(len(patterns)):\n",
    "        for j in range(len(patterns)):\n",
    "            if i != j and patterns[i][1:] == patterns[j][:-1]:\n",
    "                overlapGraph[i].append(j)\n",
    "    return overlapGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "og_dict = overlap_graph(dna_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x, y in og_dict.items():\n",
    "    for y_ in y:\n",
    "        print(\"{} -> {}\".format(dna_data[x], dna_data[y_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deBrujin(text, k):\n",
    "    patterns = [text[i:i+k-1] for i in range(len(text)-k+2)]\n",
    "    debrujin_dict = defaultdict(list)\n",
    "    for i in range(len(patterns)-1):\n",
    "        debrujin_dict[patterns[i]].append(patterns[i+1])\n",
    "    data = []\n",
    "    for x, y in debrujin_dict.items():\n",
    "        data.append(\"{} -> {}\".format(x, \", \".join(y)))\n",
    "    return data\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T -> A, G, G, G, T', 'A -> A, T, T, T', 'G -> C, G, G, A, T', 'C -> C, A']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deBrujin('TAATGCCATGGGATGTT', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TA -> AA',\n",
       " 'AA -> AT',\n",
       " 'AT -> TG, TG, TG',\n",
       " 'TG -> GC, GG, GT',\n",
       " 'GC -> CC',\n",
       " 'CC -> CA',\n",
       " 'CA -> AT',\n",
       " 'GG -> GG, GA',\n",
       " 'GA -> AT',\n",
       " 'GT -> TT']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deBrujin('TAATGCCATGGGATGTT', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TA -> AA',\n",
       " 'AA -> AT',\n",
       " 'AT -> TG, TG, TG',\n",
       " 'TG -> GG, GC, GT',\n",
       " 'GG -> GG, GA',\n",
       " 'GA -> AT',\n",
       " 'GC -> CC',\n",
       " 'CC -> CA',\n",
       " 'CA -> AT',\n",
       " 'GT -> TT']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deBrujin('TAATGGGATGCCATGTT', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deBrujin_from_kmers(kmers):\n",
    "    debrujin_dict = defaultdict(list)\n",
    "    for x in kmers:\n",
    "        debrujin_dict[x[:-1]].append(x[1:])\n",
    "    data = []\n",
    "    for x, y in debrujin_dict.items():\n",
    "        data.append(\"{} -> {}\".format(x, \", \".join(y)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CTT -> TTA',\n",
       " 'ACC -> CCA',\n",
       " 'TAC -> ACC',\n",
       " 'GGC -> GCT',\n",
       " 'GCT -> CTT',\n",
       " 'TTA -> TAC']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deBrujin_from_kmers(['CTTA','ACCA','TACC','GGCT','GCTT','TTAC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjency_list_to_dict(adjency_list):\n",
    "    adjency_dict = {}\n",
    "    for x in adjency_list:\n",
    "        x = x.replace(\" \",\"\")\n",
    "        start, ends = x.split('->')[0], x.split('->')[1].split(',')\n",
    "        adjency_dict[start] = ends\n",
    "    return adjency_dict\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "# return list that contains indegree and outdegree of each vertex\n",
    "def adjency_list_degree_list(adjency_list):\n",
    "    adjency_dict = adjency_list_to_dict(adjency_list)\n",
    "    degree_list = defaultdict(list)\n",
    "    indegree_count = Counter([x for a in adjency_dict.values() for x in a])\n",
    "    for x in adjency_dict.keys():\n",
    "        degree_list[x].append(len(adjency_dict[x]))\n",
    "        degree_list[x].append(indegree_count[x])\n",
    "    \n",
    "    end_points = set([x for a in adjency_dict.values() for x in a])\n",
    "    start_points = set(adjency_dict.keys())\n",
    "    no_outgoing_points = end_points.difference(start_points)\n",
    "    \n",
    "    for a in no_outgoing_points:\n",
    "        degree_list[a].append(0)\n",
    "        degree_list[a].append(indegree_count[a])\n",
    "    \n",
    "    return degree_list\n",
    "\n",
    "# return left number of edges\n",
    "def adjency_dict_value_length(adjency_dict):\n",
    "    a = 0\n",
    "    for x in adjency_dict.values():\n",
    "        a += len(x)\n",
    "    return a\n",
    "\n",
    "# check if the graph has eulerian cycle (input : difference of degrees in each point) \n",
    "def has_eulerian_cycle(x):\n",
    "    x.sort()\n",
    "    if x == [0]*len(x):\n",
    "        return True\n",
    "    elif x == [-1] + [0]*(len(x)-2) + [1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = '''0->2\n",
    "1->3\n",
    "2->1\n",
    "3->0,4\n",
    "6->3,7\n",
    "7->8\n",
    "8->9\n",
    "9->6'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def euler_cycle(data):\n",
    "    adjency_dict = adjency_list_to_dict(data)\n",
    "    degree_list = adjency_list_degree_list(data)\n",
    "    stack = []\n",
    "    circuit = []\n",
    "    \n",
    "    #check if graph has eulerian cycle, then set the start vertex\n",
    "    degree_diff_list = [x[0]-x[1] for x in degree_list.values()] \n",
    "    if not has_eulerian_cycle(degree_diff_list):\n",
    "        print(\"There's no eulerian cycle in this graph\")\n",
    "        return \n",
    "    elif 1 in degree_diff_list:\n",
    "        for i, x in enumerate(degree_diff_list): \n",
    "            if x == 1:\n",
    "                start_index = i\n",
    "        start_vertex = list(adjency_dict.keys())[start_index]\n",
    "    else:\n",
    "        start_vertex = random.choice(list(adjency_dict.keys()))\n",
    "    \n",
    "    location = start_vertex\n",
    "    while adjency_dict_value_length(adjency_dict) != 0:\n",
    "        if adjency_dict[location]: # if there are outgoing neighbors\n",
    "            next_location = random.choice(adjency_dict[location])  # go to that neighbor vertex\n",
    "            stack.append(location)  # add last vertex to stack\n",
    "            adjency_dict[location].remove(next_location)  # remove the edge\n",
    "            location = next_location  # update location\n",
    "        else:  # if there are no outgoing neighbors\n",
    "            circuit.append(location)\n",
    "            location = stack.pop()\n",
    "    \n",
    "    while stack:\n",
    "        circuit.append(location)\n",
    "        location = stack.pop()\n",
    "    circuit.append(location)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return circuit[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euler_path(data):\n",
    "    adjency_dict = adjency_list_to_dict(data)\n",
    "    degree_list = adjency_list_degree_list(data)\n",
    "    stack = []\n",
    "    circuit = []\n",
    "    \n",
    "    # find start vertex and end vertex\n",
    "#    end_points = set([x for a in adjency_dict.values() for x in a])\n",
    "#    start_points = set(adjency_dict.keys())\n",
    "    \n",
    "    degree_diff_list = [x[0]-x[1] for x in degree_list.values()]\n",
    "    \n",
    "    for i, x in enumerate(degree_diff_list): \n",
    "        if x == 1:\n",
    "            start_index = i\n",
    "    start_vertex = list(adjency_dict.keys())[start_index]\n",
    "    \n",
    "    # decide end vertex\n",
    "    end_vertex = None\n",
    "    for node, degrees in degree_list.items():\n",
    "        if degrees[0] == 0:\n",
    "            end_vertex = node\n",
    "\n",
    "    #if end_vertex_set:  # if there are only 0s and 1 (no -1) \n",
    "    #    (end_vertex, ) = end_vertex_set\n",
    "\n",
    "    if end_vertex:\n",
    "        # make dummy-edge end vertex and start vertex\n",
    "        adjency_dict[end_vertex] = [start_vertex]\n",
    "\n",
    "    else : # if there is both -1 and 1\n",
    "        for i, x in enumerate(degree_diff_list): \n",
    "            if x == -1:\n",
    "                end_index = i\n",
    "\n",
    "        end_vertex = list(adjency_dict.keys())[end_index] \n",
    "        adjency_dict[end_vertex].append(start_vertex)\n",
    "    \n",
    "    location = start_vertex\n",
    "    while adjency_dict_value_length(adjency_dict) != 0:\n",
    "        if adjency_dict[location]: # if there are outgoing neighbors\n",
    "            next_location = random.choice(adjency_dict[location])  # go to that neighbor vertex\n",
    "            stack.append(location)  # add last vertex to stack\n",
    "            adjency_dict[location].remove(next_location)  # remove the edge\n",
    "            location = next_location  # update location\n",
    "            print(stack)\n",
    "        else:  # if there are no outgoing neighbors\n",
    "            circuit.append(location)\n",
    "            location = stack.pop()\n",
    "            print(stack)\n",
    "        print(adjency_dict_value_length(adjency_dict))\n",
    "    \n",
    "    while stack:\n",
    "        circuit.append(location)\n",
    "        location = stack.pop()\n",
    "    circuit.append(location)\n",
    "    circuit = circuit[::-1]\n",
    "    \n",
    "    # correct the circuit (there are multiple eulerian cycles that are not right) and remove dummy edge\n",
    "    if circuit[-2:] == [end_vertex, start_vertex]:\n",
    "        real_circuit = circuit\n",
    "    else:\n",
    "        for i in range(len(circuit)-1):\n",
    "            if circuit[i:i+2] == [end_vertex, start_vertex]:\n",
    "                cut_index = i\n",
    "        real_circuit = circuit[cut_index+1:-1] + circuit[:cut_index+2] \n",
    "                \n",
    "    \n",
    "    \n",
    "    return real_circuit[:-1]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genome_reconstruction(data):\n",
    "    # data : list of kmer fractions \n",
    "    return genome_path(euler_path(deBrujin_from_kmers(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_uni = [''.join(x) for x in itertools.product('01', repeat=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {'00': [2, 2], '01': [2, 2], '10': [2, 2], '11': [2, 2]})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_uni_data = deBrujin_from_kmers(k_uni)\n",
    "k_uni_deg_list = adjency_list_degree_list(k_uni_data)\n",
    "k_uni_deg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def k_universal_strings(k):\n",
    "    k_digit_binary_list = [''.join(x) for x in itertools.product('01', repeat=k)]\n",
    "    k_universal_debrujin = deBrujin_from_kmers(k_digit_binary_list)\n",
    "    a = euler_cycle(k_universal_debrujin)\n",
    "    \n",
    "    # cause it is circular string, and euler cycle we made includes extra nodes in the end,\n",
    "    # we have to remove k-1 elements in the end\n",
    "    for i in range(k-1):\n",
    "        a.pop()\n",
    "    return genome_path(a)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1101111011010001011010100011011000100100011110100101010011101000001110110011001110011011111111001111110101010111100001101011001001101001100011000001000100001001111001000000101011011011100000000110010110000101110010100001111100011100010100100101111101110101'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_universal_strings(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_d_mer_composition(text, k, d):\n",
    "    compositions = []\n",
    "    for i in range(len(text)-2*k-d+1):\n",
    "        compositions.append(\"({}|{})\".format(text[i:i+k],text[i+k+d:i+2*k+d]))\n",
    "    #compositions.sort()\n",
    "    return compositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(TAAT|CCAT)',\n",
       " '(AATG|CATG)',\n",
       " '(ATGC|ATGG)',\n",
       " '(TGCC|TGGG)',\n",
       " '(GCCA|GGGA)',\n",
       " '(CCAT|GGAT)',\n",
       " '(CATG|GATG)',\n",
       " '(ATGG|ATGT)',\n",
       " '(TGGG|TGTT)']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_d_mer_composition('TAATGCCATGGGATGTT', 4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# input : list of debrujin graph (eulerian path) \n",
    "def string_spelled_by_gapped_patterns(gapped_patterns, k, d):\n",
    "\n",
    "    prefix_list = []\n",
    "    suffix_list = []\n",
    "    \n",
    "    for x in gapped_patterns:\n",
    "        splitted = re.split('[|]+', x)\n",
    "        prefix_list.append(splitted[0])\n",
    "        suffix_list.append(splitted[1])\n",
    "    \n",
    "    prefix_string = genome_path(prefix_list)\n",
    "    \n",
    "    #print(prefix_string)\n",
    "    suffix_string = genome_path(suffix_list)\n",
    "    #print(suffix_string)\n",
    "    \n",
    "    if prefix_string[k+d:] != suffix_string[:-(k+d)]:\n",
    "        return \"There is no string spelled by the gapped patterns\"\n",
    "    else:\n",
    "        whole_string = prefix_string + suffix_string[-(k+d):]\n",
    "        return whole_string\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prefix(gapped_pattern):\n",
    "    splitted = re.split('[|]+', gapped_pattern)\n",
    "    return splitted[0][:-1]+'|'+splitted[1][:-1]\n",
    "\n",
    "def suffix(gapped_pattern):\n",
    "    splitted = re.split('[|]+', gapped_pattern)\n",
    "    return splitted[0][1:]+'|'+splitted[1][1:]\n",
    "\n",
    "def make_debrujin_edge_from_read_pair(data):\n",
    "    return \"{} -> {}\".format(prefix(data), suffix(data))\n",
    "\n",
    "# first create euler path than create genome path (input is unordered gapped patterns)\n",
    "def create_genome_path_from_gapped_patterns(gapped_patterns, k, d):\n",
    "    \n",
    "    all_edges = []\n",
    "    \n",
    "    for x in gapped_patterns:\n",
    "        all_edges.append(make_debrujin_edge_from_read_pair(x))\n",
    "    \n",
    "    print(all_edges)\n",
    "        \n",
    "    return string_spelled_by_gapped_patterns(euler_path(all_edges), k, d)\n",
    "    \n",
    "   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_data = ['ACC|ATA','ACT|ATT','ATA|TGA','ATT|TGA','CAC|GAT','CCG|TAC','CGA|ACT','CTG|AGC','CTG|TTC','GAA|CTT','GAT|CTG','GAT|CTG','TAC|GAT','TCT|AAG','TGA|GCT','TGA|TCT','TTC|GAA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data : path information\n",
    "def maximal_non_branching_paths(data):\n",
    "    adjency_dict = adjency_list_to_dict(data)\n",
    "    degree_list = adjency_list_degree_list(data)\n",
    "    paths = []\n",
    "    for v, w_list in adjency_dict.items():\n",
    "        if degree_list[v] != [1,1]: # if v is not a 1-in-1-out node \n",
    "            if degree_list[v][0] > 0:  # if out(v) > 0\n",
    "                for w in w_list:\n",
    "                    non_branching_path = [v, w]\n",
    "                    if v == w:\n",
    "                        path.append(non_branching_path)\n",
    "                    while degree_list[w] == [1,1]:\n",
    "                        non_branching_path.append(adjency_dict[w][0])\n",
    "                        w = adjency_dict[w][0]\n",
    "                    paths.append(non_branching_path)\n",
    "\n",
    "    cycle = []\n",
    "    \n",
    "    for v, w_list in adjency_dict.items():\n",
    "        if degree_list[v] == [1,1]:\n",
    "            w = adjency_dict[v][0]\n",
    "            cycle_candidates = [v, w]\n",
    "            if degree_list[w] == [1,1]:\n",
    "                still_in_cycle = True\n",
    "\n",
    "                while still_in_cycle:\n",
    "                    if degree_list[adjency_dict[w][0]][0] == 0:\n",
    "                        still_in_cycle = False \n",
    "                    else:\n",
    "                        cycle_candidates.append(adjency_dict[w][0])\n",
    "                        w = adjency_dict[w][0]\n",
    "                    if w == v:\n",
    "                        cycle.append(cycle_candidates)\n",
    "                        still_in_cycle = False\n",
    "    \n",
    "    set_list = []\n",
    "    for a in cycle:\n",
    "        if set(a) not in set_list:\n",
    "            paths.append(a)\n",
    "            set_list.append(set(a))\n",
    "            \n",
    "    path_strings = []\n",
    "    for a in paths:\n",
    "        path_strings.append(' -> '.join(a))\n",
    "        \n",
    "    return path_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input : list of kmers -> output : possible contigs (maximal nonbranching paths in debrujin graph)\n",
    "def contigs_from_kmers(kmer_patterns):\n",
    "    data = deBrujin_from_kmers(kmer_patterns)\n",
    "    contig_paths = maximal_non_branching_paths(data)\n",
    "    contigs = []\n",
    "    for a in contig_paths:\n",
    "        nodes = a.split(' -> ')\n",
    "        contigs.append(genome_path(nodes))\n",
    "    return contigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
